{"version":"1","records":[{"hierarchy":{"lvl1":"Moving to Github!"},"type":"lvl1","url":"/content/blogs/2019/2019-05-18-moving-to-github","position":0},{"hierarchy":{"lvl1":"Moving to Github!"},"content":"GTSAM is now live on Github. Github is doing so many things right, in addition to being the go-to platform for open source: it has free continuous integration for open source projects, it supports building great web-sites, and it is itself supporting many great efforts such as VS-code and Atom. While we initially launched GTSAM on Bitbucket because of its unlimited private repos, we felt we could hold out no longer. Github, here we come :-)","type":"content","url":"/content/blogs/2019/2019-05-18-moving-to-github","position":1},{"hierarchy":{"lvl1":"Launching gtsam.org"},"type":"lvl1","url":"/content/blogs/2019/2019-05-20-gtsam-org","position":0},{"hierarchy":{"lvl1":"Launching gtsam.org"},"content":"Today we launched GTSAM’s new web presence, \n\ngtsam.org. The site is hosted by Github Pages, and is generated via \n\nJekyll, a simple static website generator.\n\nAt the moment, the page still looks rather spartan, but we’ll add a little more design features as time goes on. Plans also call for blog posts (such as this one) and tutorials, on factor graphs and on GTSAM’s implementation of it.","type":"content","url":"/content/blogs/2019/2019-05-20-gtsam-org","position":1},{"hierarchy":{"lvl1":"So, what makes legged robots different?"},"type":"lvl1","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i","position":0},{"hierarchy":{"lvl1":"So, what makes legged robots different?"},"content":"Author: Ross Hartleyemail: \n\nm​.ross​.hartley@gmail​.com\n\nThis is the first blog post in a series about using factor graphs for legged robot state estimation. It is meant to provide a high-level overview of what I call kinematic and contact factors and how they can be used in GTSAM. More details can be found in our conference papers:\n\nHybrid Contact Preintegration for Visual-Inertial-Contact State Estimation Using Factor Graphs\n\nLegged Robot State-Estimation Through Combined Forward Kinematic and Preintegrated Contact Factors\n\nIt is assumed that the reader is already familiar with the terminology and theory behind factor graph based smoothing.","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i","position":1},{"hierarchy":{"lvl1":"So, what makes legged robots different?"},"type":"lvl1","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#so-what-makes-legged-robots-different","position":2},{"hierarchy":{"lvl1":"So, what makes legged robots different?"},"content":"Factor graph methods have been widely successful for mobile robot state estimation and SLAM. A common application is the fusion of inertial data (from an IMU) with visual data (from camera and/or LiDAR sensors) to estimate the robot’s pose over time.\n\nAlthough this approach is often demonstrated on wheeled and flying robots, identical techniques can be applied to their walking brethren. What makes legged robots different, however, is the presence of additional encoder and contact sensors. As I’ll show, these extra sensor measurements can be leveraged to improve state estimation results.\n\nSensors typically found on legged robots:\n\nInertial Measurement Units (IMUs)\n\nVision Sensors (cameras, LiDARs)\n\nJoint Encoders\n\nContact Sensors\n\nAll of these sensors exist on the University of Michigan’s version of the Cassie robot (developed by \n\nAgility Robotics), which I’ll use as a concrete example.","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#so-what-makes-legged-robots-different","position":3},{"hierarchy":{"lvl1":"Factor Graph Formulation"},"type":"lvl1","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#factor-graph-formulation","position":4},{"hierarchy":{"lvl1":"Factor Graph Formulation"},"content":"Let’s see how we can create a factor graph using these 4 sensor types to estimate the trajectory of a legged robot. Each node in the graph represents the robot’s state at a particular timestep. This state includes the 3D orientation, position, and velocity of the robot’s base frame along with the IMU biases. We also include the pose of the contact frame (where the foot hits the ground) to this list of states. For simplicity, the base frame is assumed to be collocated with the inertial/vision sensor frames.\n\nEstimated States:\n\nBase pose, X\n\nBase velocity, V\n\nContact pose, C\n\nIMU biases, b\n\nEach independent sensor measurement will place a measurement factor on the graph’s nodes. Solving the factor graph consists of searching for the maximum a posteriori state estimate that minimizes the error between the predicted and actual measurements.\n\nThe robot’s inertial measurements can be incorporated into the graph using the preintegrated IMU factor built into GTSAM 4.0. This factor relates the base pose, velocity, and IMU biases across consecutive timesteps.\n\nVision data can be incorporated into the graph using a number of different factors depending on the sensor type and application. Here we will simply assume that vision provides a relative pose factor between two nodes in the graph. This can be from either visual odometry or loop closures.\n\nAt each timestep, the joint encoder data can be used to compute the relative pose transformation between the robot’s base and contact frames (through forward kinematics). This measurement be captured in a unary forward kinematic factor.\n\nOf course, adding the forward kinematic factor will not affect the optimal state estimate unless additional constraints are placed on the contact frame poses. This is achieved using a binary contact factor which uses contact measurements to infer the movement of the contact frame over time. The simplest case being contact implies zero movement of this frame. In other words, this contact factor tries to keep the contact pose fixed across timesteps where contact was measured. When contact is absent, this factor can simply be omitted in the graph.\n\nIf we know how the contact frame moves over time and we can measure the relative pose between the robot’s contact and base frames, then we have an implicit measurement of how the robot’s base moves over time.\n\nThe combined forward kinematic and contact factors can be viewed as kinematic odometry measurements of the robot’s base frame.\n\nAll together, a typical legged robot factor graph may be represented by the picture below. It will contain inertial, vision, forward kinematic, and contact factors.\n","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#factor-graph-formulation","position":5},{"hierarchy":{"lvl1":"Forward Kinematic Factor"},"type":"lvl1","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#forward-kinematic-factor","position":6},{"hierarchy":{"lvl1":"Forward Kinematic Factor"},"content":"The forward kinematics factor relates the base pose to the current contact pose using noisy encoder measurements. This is a simple relative pose factor which means we can use GTSAM’s built in BetweenFactor<Pose3> factor to implement it. We just need to determine what the factor’s covariance will be.\n\nAssuming the encoder noise is gaussian, we can map the encoder covariance to the contact pose covariance using the body manipulator Jacobian of the forward kinematics function. In general, the manipulator Jacobian maps joint angle rates to end effector twist, so it makes sense that it can be used to approximate the mapping of encoder uncertainty through the non-linearities of the robot’s kinematics.\n\nFor example, if H_BC is pose of the contact frame relative to the base frame and J_BC is the corresponding body manipulator Jacobian, the forward kinematic factor can be implemented using the following GTSAM code:Matrix6 FK_Cov = J_BC * encoder_covariance_matrix * J_BC.transpose();\nBetweenFactor<Pose3> forward_kinematics_factor(X(node), C(node), H_BC, noiseModel::Gaussian::Covariance(FK_cov));","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#forward-kinematic-factor","position":7},{"hierarchy":{"lvl1":"Rigid Contact Factor"},"type":"lvl1","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#rigid-contact-factor","position":8},{"hierarchy":{"lvl1":"Rigid Contact Factor"},"content":"Contact factors come in a number of different flavors depending on the assumptions we want to make about the contact sensor measurements. However, they will all provide a measurement of contact frame odometry (i.e. how to foot will move over time).\n\nFor example, in the simplest case, perhaps measuring contact implies that the entire pose of the foot remains fixed. We can call this rigid contact, and it may be a good assumption for many humanoid robots that have large, flat feet. In contrast, we could alternatively assume a point contact, where the position of the contact frame remains fixed, but the foot is free to rotate.\n\nFor now, lets look at how we can implement a rigid contact factor.  Again, when contact is measured, we assume there is no relative change in the contact frame pose. In other words, the contact frame velocity is zero. This can be implemented in GTSAM using a BetweenFactor<Pose3> factor, where the measurement is simply the identity element.BetweenFactor<Pose3> contact_factor(C(node-1), C(node), Pose3::identity(), noiseModel::Gaussian::Covariance(Sigma_ij);\n\nSome potential foot slip can be accommodated through the factor’s covariance, Sigma_ij. If we are highly confident that the foot remained fixed on the ground, this covariance should be small. A large covariance implies less confidence in this assumption.\n\nOne idea is simply assuming Gaussian noise on the contact frame velocity. In this case, the factor’s covariance will grow with the length of time between the graph nodes. Another idea is to use contact force information to model the factor’s covariance.","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#rigid-contact-factor","position":9},{"hierarchy":{"lvl1":"Rigid Contact Factor","lvl2":"What happens when contact is made/broken?"},"type":"lvl2","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#what-happens-when-contact-is-made-broken","position":10},{"hierarchy":{"lvl1":"Rigid Contact Factor","lvl2":"What happens when contact is made/broken?"},"content":"Using the formulation above, every time contact is made or broken, a new node has to be added to the factor graph. This stems from our contact measurement assumption. When the robot loses contact, we have no way to determine the foot movement using contact sensors alone. Our only choice is to add a new node in the graph and omit the contact factor until contact is regained.\n\nThis may not be an issue for some slow walking robots where contact states change infrequently, but what about a running hexapod? In that case, the numerous contact changes will lead to an explosion in the number of nodes (and optimization variables) needed in the graph. This ultimately affects the performance of the state estimator by increasing the time it takes to solve the underlying optimization problem.\n\nThankfully, there is a way around this problem.","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#what-happens-when-contact-is-made-broken","position":11},{"hierarchy":{"lvl1":"Hybrid Rigid Contact Factor"},"type":"lvl1","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#hybrid-rigid-contact-factor","position":12},{"hierarchy":{"lvl1":"Hybrid Rigid Contact Factor"},"content":"During many types of walking gaits, when one contact is broken, another is made. For example, with bipedal walking, left stance is followed by right stance, then left, then right, and so on. The order on a hexapod might be more complicated, but one fact remains: there is often (at least) one foot on the ground at all times. We can use this knowledge to improve performance in our factor graph by limiting the insertion rate of new graph nodes.\n\nIf we choose two arbitrary times (potentially far apart), any single contact is likely to have been broken at some point between them. However, there may be a chain of contact frames that we can swap through to maintain the notion of contact with the environment. Each consecutive pair of contact frames in this chain are related to each other through forward kinematics.\n\nFor example, lets say our biped robot switched from left stance (L1), to right stance (R1), back to left stance (L2) again. During the L1 phase, we can assume the contact frame pose remained fixed (zero velocity). When the robot switches from L1 to R1, we can map this contact frame from the left to the right foot using the encoder measurements and forward kinematics (since both feet are on the ground at this time). During the R1 phase, we again assume that the contact pose remains fixed. When the second swap happens, R1 to L2, we map the contact frame back to left foot using the encoder measurements and a (different) forward kinematics function. So in effect, we have tracked the movement of the contact frame across two contact switches. This relative pose measurement provides odometry for the contact frame and can be used to create a hybrid rigid contact factor. Using this method, nodes can now be added to the graph at arbitrary times, and do not have to be added when contact is made/broken (unless all feet come off the ground).\n\nLike the original rigid contact factor, the hybrid version can be created using GTSAM’s BetweenFactor<Pose3> factor, where delta_Hij is the cumulative change in contact pose across all contact switches. The factor’s covariance is typically larger as it needs to account for the uncertainty in each swap’s forward kinematics.BetweenFactor<Pose3> hybrid_contact_factor(C(node-1), C(node), delta_Hij, noiseModel::Gaussian::Covariance(Sigma_ij);","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#hybrid-rigid-contact-factor","position":13},{"hierarchy":{"lvl1":"Coming soon..."},"type":"lvl1","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#coming-soon","position":14},{"hierarchy":{"lvl1":"Coming soon..."},"content":"I briefly discussed two types of factors that can be used to improve legged robot state estimation: the forward kinematic factor and the (hybrid) rigid contact factor. Combining these two factors allows for kinematic odometry to be added alongside other measurements (inertial, vision, etc.) when building up a factor graph.\n\nIn particular, when developing the rigid contact factor, we made the strong assumption that a contact measurement implies zero angular and linear velocity of the contact frame. The factor tries to keep the entire pose of the foot fixed across two timesteps. This assumption may not be valid for all types of walking robots. In fact, it doesn’t even hold for the Cassie robot! The roll angle about Cassie’s foot is unactuated and free to move during walking. In the next post, I will discuss the (hybrid) point contact factor which makes no assumptions about the angular velocity of the contact frame.","type":"content","url":"/content/blogs/2019/2019-09-18-legged-robot-factors-part-i#coming-soon","position":15},{"hierarchy":{"lvl1":"About"},"type":"lvl1","url":"/content/about","position":0},{"hierarchy":{"lvl1":"About"},"content":"GTSAM is a sensor fusion library based on factor graphs, developed by Frank Dellaert and his students in Georgia Tech’s BORG Lab, as well as numerous open source contributors.\n\nCurrent Georgia Tech BORG Lab contributors include:\n\nVarun Agrawal\n\nAbhinav Jain\n\nMatthew Sklar\n\nMandy Xie\n\nBelow are the many Georgia Tech BORG lab alumni with their current afffiliation, if known:\n\nJeremy Aguilon, Facebook\n\nPablo Alcantarilla, iRobot\n\nSungtae An\n\nDoru Balcan, Bank of America\n\nChris Beall, Nuro\n\nLuca Carlone, MIT\n\nKrunal Chande, Fyusion\n\nAlex Cunningham, TRI\n\nJing Dong, Facebook Reality Labs\n\nPaul Drews, TRI\n\nAlireza Fathi, Google\n\nEohan George\n\nAlex Hagiopol, Microsoft\n\nViorela Ila, U. Sydney\n\nVadim Indelman, the Technion\n\nDavid Jensen, GTRI\n\nYong-Dian Jian, Nvidia\n\nMichael Kaess, Carnegie Mellon\n\nAbhijit Jundu, Google\n\nZhaoyang Lv, Facebook Reality Labs\n\nAndrew Melim, Oculus\n\nKai Ni, Holomatic\n\nCarlos Nieto, UCSD\n\nDuy-Nguyen Ta, TRI\n\nManohar Paluri, Facebook\n\nChristian Potthast, USC\n\nRichard Roberts, Google X\n\nGrant Schindler, Consultant\n\nNatesh Srinivasan, Apple\n\nAlex Trevor, Fyusion\n\nStephen Williams, BossaNova\n\nIn addition, we have had contrubutions from many others at different institutions and labs, again listed below with their current affiliations if known:\n\nAbe Bachrach, Skydio\n\nJose Luis Blanco-Claraco, University of Almería\n\nMatthew Broadway\n\nAdam Bry, Skydio\n\nMike Bosse, ETHZ\n\nGareth Cross, Skydio\n\nChristian Forster, Oculus Zurich\n\nPaul Furgale, Oculus Zurich\n\nHayk Martiros, Skydio\n\nEllon Paiva, LAAS-CNRS\n\nDavid M. Rosen, MIT\n\nThomas Schneider, ETHZ\n\nHannes Sommer, ETHZ\n\nAkash Patel, Georgia Tech\n\nChristian Vaugelade Berg, EasyMile\n\nIf you contributed but do not see your name listed above, or you are listed with an incorrect affiliation, please consider making a PR for this file at the \n\ngtsam.org github repo.","type":"content","url":"/content/about","position":1},{"hierarchy":{"lvl1":"Blog"},"type":"lvl1","url":"/content/blog","position":0},{"hierarchy":{"lvl1":"Blog"},"content":"","type":"content","url":"/content/blog","position":1},{"hierarchy":{"lvl1":"Build"},"type":"lvl1","url":"/content/build-project","position":0},{"hierarchy":{"lvl1":"Build"},"content":"Configurations\n\nTested Compilers\n\nTested Systems\n\nGCC 4.2-7.3\n\nUbuntu 16.04 - 18.04\n\nOS X Clang 2.9-10.0\n\nMacOS 10.6 - 10.14, 15.2-15.3\n\nOS X GCC 4.2\n\nWindows 7, 8, 8.1, 10\n\nMSVC 2017\n\n\n\nTo build GTSAM from source, clone or download the latest release from the \n\nGTSAM Github repo. Then follow the build & install instructions below.","type":"content","url":"/content/build-project","position":1},{"hierarchy":{"lvl1":"Build","lvl2":"Quickstart"},"type":"lvl2","url":"/content/build-project#quickstart","position":2},{"hierarchy":{"lvl1":"Build","lvl2":"Quickstart"},"content":"In the root library folder execute:#!bash\n$ mkdir build\n$ cd build\n$ cmake ..\n$ make check (optional, runs unit tests)\n$ make install","type":"content","url":"/content/build-project#quickstart","position":3},{"hierarchy":{"lvl1":"Build","lvl3":"Important Installation Notes","lvl2":"Quickstart"},"type":"lvl3","url":"/content/build-project#important-installation-notes","position":4},{"hierarchy":{"lvl1":"Build","lvl3":"Important Installation Notes","lvl2":"Quickstart"},"content":"GTSAM requires the following libraries to be installed on your system:\n\nBOOST version 1.43 or greater (install through Linux repositories or MacPorts)\n\nCmake version 3.0 or higher\n\nSupport for XCode 4.3 command line tools on Mac requires CMake 2.8.8 or higher\n\nOptional dependent libraries:\n\nIf TBB is installed and detectable by CMake GTSAM will use it automatically. Ensure that CMake prints Use Intel TBB : Yes. To disable the use of TBB,\ndisable the CMake flag GTSAM_WITH_TBB (enabled by default). On Ubuntu, TBB may be installed from the Ubuntu repositories, and for other platforms it\nmay be downloaded from \n\nhere.\n\nGTSAM may be configured to use MKL by toggling GTSAM_WITH_EIGEN_MKL and GTSAM_WITH_EIGEN_MKL_OPENMP to ON.\nHowever, best performance is usually achieved with MKL disabled. We therefore advise you to benchmark your problem before using MKL.\n\nGTSAM makes extensive use of debug assertions, and we highly recommend you work in Debug mode while developing (not enabled by default). Likewise, it is imperative that you switch to release mode when running finished code and for timing. GTSAM will run up to 10x faster in Release mode! See the end of this document for\nadditional debugging tips.\n\nGTSAM has \n\nDoxygen documentation. To generate, run make doc from your build directory, or refer to the \n\nstatically generated version on this website.\n\nThe instructions below install the library to the default system install path and build all components. From a terminal, starting in the root library folder, execute the commands below for an out-of-source build. This will build the library and unit tests, run all of the unit tests, and then install the library itself.  $ mkdir build\n  $ cd build\n  $ cmake ..\n  $ make check (optional, runs unit tests)\n  $ make install","type":"content","url":"/content/build-project#important-installation-notes","position":5},{"hierarchy":{"lvl1":"Build","lvl3":"CMake Configuration Options and Details","lvl2":"Quickstart"},"type":"lvl3","url":"/content/build-project#cmake-configuration-options-and-details","position":6},{"hierarchy":{"lvl1":"Build","lvl3":"CMake Configuration Options and Details","lvl2":"Quickstart"},"content":"GTSAM has a number of options that can be configured, which is best done with\none of the following:\n\nccmake:      the curses GUI for cmake\n\ncmake-gui:   a real GUI for cmake","type":"content","url":"/content/build-project#cmake-configuration-options-and-details","position":7},{"hierarchy":{"lvl1":"Build","lvl3":"Important Options:","lvl2":"Quickstart"},"type":"lvl3","url":"/content/build-project#important-options","position":8},{"hierarchy":{"lvl1":"Build","lvl3":"Important Options:","lvl2":"Quickstart"},"content":"","type":"content","url":"/content/build-project#important-options","position":9},{"hierarchy":{"lvl1":"Build","lvl4":"CMAKE_BUILD_TYPE","lvl3":"Important Options:","lvl2":"Quickstart"},"type":"lvl4","url":"/content/build-project#cmake-build-type","position":10},{"hierarchy":{"lvl1":"Build","lvl4":"CMAKE_BUILD_TYPE","lvl3":"Important Options:","lvl2":"Quickstart"},"content":"We support several build configurations for GTSAM (case insensitive)\n\n`cmake -DCMAKE_BUILD_TYPE=[Option] ..`\n\nDebug: All error checking options on, no optimization. Use for development of new features and fixing issues.\n\nRelease: Optimizations turned on, no debug symbols.\n\nTiming: Adds ENABLE_TIMING flag to provide statistics on operation\n\nProfiling: Standard configuration for use during profiling\n\nRelWithDebInfo: Same as Release, but with the - g flag\nfor debug symbols","type":"content","url":"/content/build-project#cmake-build-type","position":11},{"hierarchy":{"lvl1":"Build","lvl4":"CMAKE_INSTALL_PREFIX","lvl3":"Important Options:","lvl2":"Quickstart"},"type":"lvl4","url":"/content/build-project#cmake-install-prefix","position":12},{"hierarchy":{"lvl1":"Build","lvl4":"CMAKE_INSTALL_PREFIX","lvl3":"Important Options:","lvl2":"Quickstart"},"content":"The install folder. The default is typically /usr/local/ .\nTo configure to install to your home directory, you could execute:\n`cmake -DCMAKE_INSTALL_PREFIX:PATH=$HOME ..`","type":"content","url":"/content/build-project#cmake-install-prefix","position":13},{"hierarchy":{"lvl1":"Build","lvl4":"GTSAM_TOOLBOX_INSTALL_PATH","lvl3":"Important Options:","lvl2":"Quickstart"},"type":"lvl4","url":"/content/build-project#gtsam-toolbox-install-path","position":14},{"hierarchy":{"lvl1":"Build","lvl4":"GTSAM_TOOLBOX_INSTALL_PATH","lvl3":"Important Options:","lvl2":"Quickstart"},"content":"The Matlab toolbox will be installed in a subdirectory of this folder, called gtsam.cmake -DGTSAM_TOOLBOX_INSTALL_PATH:PATH=$HOME/toolbox ..","type":"content","url":"/content/build-project#gtsam-toolbox-install-path","position":15},{"hierarchy":{"lvl1":"Build","lvl4":"GTSAM_BUILD_CONVENIENCE_LIBRARIES","lvl3":"Important Options:","lvl2":"Quickstart"},"type":"lvl4","url":"/content/build-project#gtsam-build-convenience-libraries","position":16},{"hierarchy":{"lvl1":"Build","lvl4":"GTSAM_BUILD_CONVENIENCE_LIBRARIES","lvl3":"Important Options:","lvl2":"Quickstart"},"content":"This is a build option to allow for tests in subfolders to be linked against convenience libraries rather than the full libgtsam.\nSet with the command line as follows:cmake -DGTSAM_BUILD_CONVENIENCE_LIBRARIES:OPTION=ON ..\n\nON (Default): This builds convenience libraries and links tests against them.This option is suggested for gtsam developers, as it is possible to build and run tests without first building the rest of the library, and speeds up compilation for a single test.The downside of this option is that it will build the entire library again to build the full libgtsam library, so build / install will be slower.\n\nOFF: This will build all of libgtsam before any of the tests, and then link all of the tests at once.This option is best\nfor users of GTSAM, as it avoids rebuilding the entirety of gtsam an extra time.","type":"content","url":"/content/build-project#gtsam-build-convenience-libraries","position":17},{"hierarchy":{"lvl1":"Build","lvl4":"GTSAM_BUILD_UNSTABLE","lvl3":"Important Options:","lvl2":"Quickstart"},"type":"lvl4","url":"/content/build-project#gtsam-build-unstable","position":18},{"hierarchy":{"lvl1":"Build","lvl4":"GTSAM_BUILD_UNSTABLE","lvl3":"Important Options:","lvl2":"Quickstart"},"content":"Enable build and install for libgtsam_unstable library.\nSet with the command line as follows:cmake -DGTSAM_BUILD_UNSTABLE:OPTION=ON ..\n\nON (Default): When enabled, libgtsam_unstable will be built and installed with the same options as \n\nlibgtsam.In addition, if tests are enabled, the unit tests will be built as well.The Matlab toolbox will also be generated\nif the matlab toolbox is enabled, installing into a folder called gtsam_unstable.\n\nOFF: If disabled, no gtsam_unstable code will be included in build or install.","type":"content","url":"/content/build-project#gtsam-build-unstable","position":19},{"hierarchy":{"lvl1":"Build","lvl4":"MEX_COMMAND","lvl3":"Important Options:","lvl2":"Quickstart"},"type":"lvl4","url":"/content/build-project#mex-command","position":20},{"hierarchy":{"lvl1":"Build","lvl4":"MEX_COMMAND","lvl3":"Important Options:","lvl2":"Quickstart"},"content":"Path to the mex compiler. Defaults to assume the path is included in your shell 's PATH environment variable. mex is installed with matlab at $MATLABROOT/bin/mex. The correct value for  MATLABROOT can be found by executing the command matlabroot in MATLAB","type":"content","url":"/content/build-project#mex-command","position":21},{"hierarchy":{"lvl1":"Build","lvl3":"Running the unit tests","lvl2":"Quickstart"},"type":"lvl3","url":"/content/build-project#running-the-unit-tests","position":22},{"hierarchy":{"lvl1":"Build","lvl3":"Running the unit tests","lvl2":"Quickstart"},"content":"make check will build and run all of the tests.Note that the tests will only be built when using the “check” targets, to prevent make install from building the tests unnecessarily.\n\nYou can also run make timing to build all of the timing scripts.\nTo run check on a particular module only, run make check.[subfolder] , so to run just the geometry tests, run make check.geometry .\n\nIndividual tests can be run by appending .run to the name of the test,\nfor example, to run testMatrix, run make testMatrix.run .","type":"content","url":"/content/build-project#running-the-unit-tests","position":23},{"hierarchy":{"lvl1":"Build","lvl3":"Performance","lvl2":"Quickstart"},"type":"lvl3","url":"/content/build-project#performance","position":24},{"hierarchy":{"lvl1":"Build","lvl3":"Performance","lvl2":"Quickstart"},"content":"Here are some tips to get the best possible performance out of GTSAM.\n\nBuild in Release mode. GTSAM will run up to 10x faster compared to Debug\nmode.\n\nEnable TBB. On modern processors with multiple cores, this can easily speed up optimization by 30 - 50 %. Please note that this may not be true\nfor very small problems where the overhead of dispatching work to multiple threads outweighs the benefit. We recommend that you benchmark your problem with / without TBB.\n\nAdd -march=native to GTSAM_CMAKE_CXX_FLAGS. A performance gain of\n25 - 30 % can be expected on modern processors. Note that this affects the portability of your executable. It may not run when copied to another system with older / different processor architecture. Also note that all dependent projects must be compiled with the same flag, or segfaults and other undefined behavior may result.\n\nPossibly enable MKL. Please note that our benchmarks have shown that this helps only in very limited cases, and actually hurts performance in the usual case. We therefore recommend that you do not enable MKL, unless you have benchmarked it on your problem and have verified that it improves performance.","type":"content","url":"/content/build-project#performance","position":25},{"hierarchy":{"lvl1":"Build","lvl3":"Debugging tips","lvl2":"Quickstart"},"type":"lvl3","url":"/content/build-project#debugging-tips","position":26},{"hierarchy":{"lvl1":"Build","lvl3":"Debugging tips","lvl2":"Quickstart"},"content":"Another useful debugging symbol is _GLIBCXX_DEBUG, which enables debug checks and safe containers in the standard C++ library and makes problems much easier to find.\n\nNOTE: The native Snow Leopard g++compiler / library contains a bug that makes it impossible to use _GLIBCXX_DEBUG. MacPorts g++compilers do work with it though.\n\nNOTE: If _GLIBCXX_DEBUG is used to compile gtsam, anything that links against gtsam will need to be compiled with _GLIBCXX_DEBUG as well, due to the use of header - only Eigen.","type":"content","url":"/content/build-project#debugging-tips","position":27},{"hierarchy":{"lvl1":"Build","lvl3":"Installing MKL on Linux","lvl2":"Quickstart"},"type":"lvl3","url":"/content/build-project#installing-mkl-on-linux","position":28},{"hierarchy":{"lvl1":"Build","lvl3":"Installing MKL on Linux","lvl2":"Quickstart"},"content":"Intel has a guide\nfor installing MKL on Linux through APT repositories \n\nhere.\n\nAfter following the instructions, add the following to your ~/.bashrc (and afterwards, open a new terminal before compiling GTSAM):\nLD_PRELOAD\nneed only be set if you are building the cython wrapper to use GTSAM from python.source /opt/intel/mkl/bin/mklvars.sh intel64\nexport LD_PRELOAD=\"$LD_PRELOAD:/opt/intel/mkl/lib/intel64/libmkl_core.so:/opt/intel/mkl/lib/intel64/libmkl_sequential.so\"\n\nTo use MKL in GTSAM pass the flag -DGTSAM_WITH_EIGEN_MKL=ON to cmake.\n\nThe LD_PRELOAD fix seems to be related to a well known problem with MKL which leads to lots of undefined symbol errors, for example:\n\nhttps://​software​.intel​.com​/en​-us​/forums​/intel​-math​-kernel​-library​/topic​/300857\n\nhttps://​software​.intel​.com​/en​-us​/forums​/intel​-distribution​-for​-python​/topic​/628976\n\nhttps://​groups​.google​.com​/a​/continuum​.io​/forum​/​#!topic​/anaconda​/J3YGoef64z8\n\nFailing to specify LD_PRELOAD may lead to errors such as:\nImportError: /opt/intel/mkl/lib/intel64/libmkl_vml_avx2.so: undefined symbol: mkl_serv_getenv\nor\nIntel MKL FATAL ERROR: Cannot load libmkl_avx2.so or libmkl_def.so.\nwhen importing GTSAM using the cython wrapper in python.","type":"content","url":"/content/build-project#installing-mkl-on-linux","position":29},{"hierarchy":{"lvl1":"Docs"},"type":"lvl1","url":"/content/docs","position":0},{"hierarchy":{"lvl1":"Docs"},"content":"For a hands-on mathematical introduction see the tutorial on \n\nFactor Graphs and GTSAM.","type":"content","url":"/content/docs","position":1},{"hierarchy":{"lvl1":"Docs","lvl2":"API and Wrapper Documentation"},"type":"lvl2","url":"/content/docs#api-and-wrapper-documentation","position":2},{"hierarchy":{"lvl1":"Docs","lvl2":"API and Wrapper Documentation"},"content":"Currently, detailed API documentation is available only for C++ via the \n\nC++ Doxygen generated site.\n\nGTSAM comes with a python wrapper (see cython directory) and a matlab wrapper (see matlab directory), and for prototyping with GTSAM we highly recommend using one of the above. The auto-generated API documentation for python/MATLAB is limited to the number and type of input arguments, and again the \n\ndoxygen docs provide the details.","type":"content","url":"/content/docs#api-and-wrapper-documentation","position":3},{"hierarchy":{"lvl1":"Docs","lvl2":"Notes on GTSAM"},"type":"lvl2","url":"/content/docs#notes-on-gtsam","position":4},{"hierarchy":{"lvl1":"Docs","lvl2":"Notes on GTSAM"},"content":"GTSAM Concepts\n\nThe Preintegrated IMU Factor\n\nMigrating from GTSAM 3\n\nContributing to GTSAM","type":"content","url":"/content/docs#notes-on-gtsam","position":5},{"hierarchy":{"lvl1":"Docs","lvl2":"Additional Information"},"type":"lvl2","url":"/content/docs#additional-information","position":6},{"hierarchy":{"lvl1":"Docs","lvl2":"Additional Information"},"content":"There is a GTSAM users Google group for general discussion.","type":"content","url":"/content/docs#additional-information","position":7},{"hierarchy":{"lvl1":"Get Started"},"type":"lvl1","url":"/content/get-started","position":0},{"hierarchy":{"lvl1":"Get Started"},"content":"","type":"content","url":"/content/get-started","position":1},{"hierarchy":{"lvl1":"Get Started","lvl2":"Install GTSAM from Source"},"type":"lvl2","url":"/content/get-started#install-gtsam-from-source","position":2},{"hierarchy":{"lvl1":"Get Started","lvl2":"Install GTSAM from Source"},"content":"In the root library folder execute:#!bash\n$ mkdir build\n$ cd build\n$ cmake ..\n$ make check (optional, runs unit tests)\n$ make install\n\nPrerequisites:\n\nBoost >= 1.43 (Ubuntu: sudo apt-get install libboost-all-dev)\n\nCMake >= 3.0 (Ubuntu: sudo apt-get install cmake)\n\nA modern compiler, i.e., at least gcc 4.7.3 on Linux.\n\nOptional prerequisites - used automatically if findable by CMake:\n\nIntel Threaded Building Blocks (TBB) (Ubuntu: sudo apt-get install libtbb-dev)\n\nIntel Math Kernel Library (MKL) (Ubuntu: \n\ninstalling using APT)\n\nSee \n\nBuild for more installation information\n\nNote that MKL may not provide a speedup in all cases. Make sure to benchmark your problem with and without MKL.","type":"content","url":"/content/get-started#install-gtsam-from-source","position":3},{"hierarchy":{"lvl1":"Get Started","lvl2":"Install GTSAM from Ubuntu PPA"},"type":"lvl2","url":"/content/get-started#install-gtsam-from-ubuntu-ppa","position":4},{"hierarchy":{"lvl1":"Get Started","lvl2":"Install GTSAM from Ubuntu PPA"},"content":"GTSAM can be installed on Ubuntu via \n\nthese PPA repositories as well.\nAt present (Nov 2020), packages for Xenial (u16.04), Bionic (u18.04), and Focal (u20.04) are published.","type":"content","url":"/content/get-started#install-gtsam-from-ubuntu-ppa","position":5},{"hierarchy":{"lvl1":"Get Started","lvl3":"Add PPA for GTSAM nightly builds (develop branch)","lvl2":"Install GTSAM from Ubuntu PPA"},"type":"lvl3","url":"/content/get-started#add-ppa-for-gtsam-nightly-builds-develop-branch","position":6},{"hierarchy":{"lvl1":"Get Started","lvl3":"Add PPA for GTSAM nightly builds (develop branch)","lvl2":"Install GTSAM from Ubuntu PPA"},"content":"# Add PPA\nsudo add-apt-repository ppa:borglab/gtsam-develop\nsudo apt update  # not necessary since Bionic\n# Install:\nsudo apt install libgtsam-dev libgtsam-unstable-dev","type":"content","url":"/content/get-started#add-ppa-for-gtsam-nightly-builds-develop-branch","position":7},{"hierarchy":{"lvl1":"Get Started","lvl3":"Add PPA for the latest GTSAM 4.x stable release","lvl2":"Install GTSAM from Ubuntu PPA"},"type":"lvl3","url":"/content/get-started#add-ppa-for-the-latest-gtsam-4-x-stable-release","position":8},{"hierarchy":{"lvl1":"Get Started","lvl3":"Add PPA for the latest GTSAM 4.x stable release","lvl2":"Install GTSAM from Ubuntu PPA"},"content":"# Add PPA\nsudo add-apt-repository ppa:borglab/gtsam-release-4.0\nsudo apt update  # not necessary since Bionic\n# Install:\nsudo apt install libgtsam-dev libgtsam-unstable-dev","type":"content","url":"/content/get-started#add-ppa-for-the-latest-gtsam-4-x-stable-release","position":9},{"hierarchy":{"lvl1":"Get Started","lvl2":"Install GTSAM from Arch Linux AUR"},"type":"lvl2","url":"/content/get-started#install-gtsam-from-arch-linux-aur","position":10},{"hierarchy":{"lvl1":"Get Started","lvl2":"Install GTSAM from Arch Linux AUR"},"content":"Note: Installing GTSAM on Arch Linux is not tested by the GTSAM developers.\n\nGTSAM is available in the Arch User Repository\n(\n\nAUR) as\n\n\ngtsam.\n\nNote you can manually install the package by following the instructions on the\n\n\nArch Wiki\nor use an \n\nAUR helper like\n\n\nyay\n(recommended for ease of install).\n\nIt is also recommended to use the\n\n\narch4edu\nrepository. They are hosting many packages related to education and research,\nincluding robotics such as ROS. Adding a repository allows for you to install\nbinaries of packages, instead of compiling them from source.\nThis will greatly speed up your installation time. Visit \n\nhere to add and use arch4edu.","type":"content","url":"/content/get-started#install-gtsam-from-arch-linux-aur","position":11},{"hierarchy":{"lvl1":"Get Started","lvl3":"Install GTSAM","lvl2":"Install GTSAM from Arch Linux AUR"},"type":"lvl3","url":"/content/get-started#install-gtsam","position":12},{"hierarchy":{"lvl1":"Get Started","lvl3":"Install GTSAM","lvl2":"Install GTSAM from Arch Linux AUR"},"content":"yay -S gtsam\n\nor","type":"content","url":"/content/get-started#install-gtsam","position":13},{"hierarchy":{"lvl1":"Get Started","lvl3":"Install GTSAM with Intel Accelerations","lvl2":"Install GTSAM from Arch Linux AUR"},"type":"lvl3","url":"/content/get-started#install-gtsam-with-intel-accelerations","position":14},{"hierarchy":{"lvl1":"Get Started","lvl3":"Install GTSAM with Intel Accelerations","lvl2":"Install GTSAM from Arch Linux AUR"},"content":"yay -S gtsam-mkl\n\nTo discuss any issues related to this package refer to the comments section on\nthe AUR page of gtsam \n\nhere.","type":"content","url":"/content/get-started#install-gtsam-with-intel-accelerations","position":15},{"hierarchy":{"lvl1":"GTSAM 4.1"},"type":"lvl1","url":"/content","position":0},{"hierarchy":{"lvl1":"GTSAM 4.1"},"content":"Factor graphs for Sensor Fusion in Robotics.\n\nGTSAM 4.1 is a BSD-licensed C++ library that implements sensor fusion for robotics and computer vision applications, including SLAM (Simultaneous Localization and Mapping), VO (Visual Odometry), and SFM (Structure from Motion). It uses factor graphs and Bayes networks as the underlying computing paradigm rather than sparse matrices to optimize for the most probable configuration or an optimal plan.\n\nCoupled with a capable sensor front-end (not provided here), GTSAM powers many impressive autonomous systems, in both academia and industry.","type":"content","url":"/content","position":1},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM"},"type":"lvl1","url":"/content/tutorial","position":0},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM"},"content":"This is an updated version of the 2012 tech-report \n\nFactor Graphs and GTSAM: A Hands-on Introduction by \n\nFrank Dellaert. A more thorough introduction to the use of factor graphs in robotics is the 2017 article \n\nFactor graphs for robot perception by Frank Dellaert and Michael Kaess.","type":"content","url":"/content/tutorial","position":1},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"Overview"},"type":"lvl2","url":"/content/tutorial#overview","position":2},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"Overview"},"content":"Factor graphs are graphical models (\n\nKoller and Friedman, 2009) that are well suited to modeling complex estimation problems, such as Simultaneous Localization and Mapping (SLAM) or Structure from Motion (SFM). You might be familiar with another often used graphical model, Bayes networks, which are directed acyclic graphs. A factor graph, however, is a bipartite graph consisting of factors connected to variables. The variables represent the unknown random variables in the estimation problem, whereas the factors represent probabilistic constraints on those variables, derived from measurements or prior knowledge. In the following sections I will illustrate this with examples from both robotics and vision.\n\nThe GTSAM toolbox (GTSAM stands for “Georgia Tech Smoothing and Mapping”) toolbox is a BSD-licensed C++ library based on factor graphs, developed at the Georgia Institute of Technology by myself, many of my students, and collaborators. It provides state of the art solutions to the SLAM and SFM problems, but can also be used to model and solve both simpler and more complex estimation problems. It also provides a MATLAB interface which allows for rapid prototype development, visualization, and user interaction.\n\nGTSAM exploits sparsity to be computationally efficient. Typically measurements only provide information on the relationship between a handful of variables, and hence the resulting factor graph will be sparsely connected. This is exploited by the algorithms implemented in GTSAM to reduce computational complexity. Even when graphs are too dense to be handled efficiently by direct methods, GTSAM provides iterative methods that are quite efficient regardless.\n\nYou can download the latest version of GTSAM from our \n\nGithub repo.","type":"content","url":"/content/tutorial#overview","position":3},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"1. Factor Graphs"},"type":"lvl2","url":"/content/tutorial#id-1-factor-graphs","position":4},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"1. Factor Graphs"},"content":"Let us start with a one-page primer on factor graphs, which in no way replaces the excellent and detailed reviews by \n\nKschischang & Loeliger (2001) and \n\nLoeliger (2004) (2004).\n\n\n\nFigure 1:An HMM, unrolled over three time-steps, represented by a Bayes net.\n\nFigure 1 shows the Bayes network for a hidden Markov model (HMM) over three time steps. In a Bayes net, each node is associated with a conditional density: the top Markov chain encodes the prior P(X_1) and transition probabilities P(X_2|X_1) and P(X_3|X_2), whereas measurements Z_t depend only on the state X_t, modeled by conditional densities P(Z_t|X_t).\n\nGiven known measurements z_1, z_2, and z_3 we are interested in the hidden state sequence (X_1, X_2, X_3) that maximizes the posterior probability P(X_1, X_2, X_3 | Z_1 = z_1, Z_2 = z_2, Z_3 = z_3). Since the measurements z_1, z_2, and z_3 are known, the posterior is proportional to the product of six factors, three of which derive from the the Markov chain, and three likelihood factors defined as L(X_t; z) \\propto P(Z_t = z | X_t):P(X_1, X_2, X_3 | Z_1 = z_1, Z_2 = z_2, Z_3 = z_3) \\propto P(X_1) P(X_2|X_1) P(X_3|X_2) L(X_1; z_1) L(X_2; z_2) L(X_3; z_3)\n\n\n\nFigure 2:An HMM with observed measurements, unrolled over time, represented as a factor graph.\n\nThis motivates a different graphical model, a factor graph, in which we only represent the unknown variables X_1, X_2, and X_3, connected to factors that encode probabilistic information on them, as in Figure 2. To do maximum a-posteriori (MAP) inference, we then maximize the productf(X_1, X_2, X_3) = \\prod f_i(\\mathscr{X}_i)\n\ni.e., the value of the factor graph. It should be clear from the figure that the connectivity of a factor graph encodes, for each factor f_i, which subset of variables  (\\mathscr{X}_i it depends on. In the examples below, we use factor graphs to model more complex MAP inference problems in robotics.","type":"content","url":"/content/tutorial#id-1-factor-graphs","position":5},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"2. Modeling Robot Motion"},"type":"lvl2","url":"/content/tutorial#id-2-modeling-robot-motion","position":6},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"2. Modeling Robot Motion"},"content":"","type":"content","url":"/content/tutorial#id-2-modeling-robot-motion","position":7},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.1 Modeling with Factor Graphs","lvl2":"2. Modeling Robot Motion"},"type":"lvl3","url":"/content/tutorial#id-2-1-modeling-with-factor-graphs","position":8},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.1 Modeling with Factor Graphs","lvl2":"2. Modeling Robot Motion"},"content":"Before diving into a SLAM example, let us consider the simpler problem of modeling robot motion. This can be done with a continuous Markov chain, and provides a gentle introduction to GTSAM.\n\n\n\nFigure 3:Factor graph for robot localization.\n\nThe factor graph for a simple example is shown in Figure 3. There are three variables x_1, x_2, and x_3 which represent the poses of the robot over time, rendered in the figure by the open-circle variable nodes. In this example, we have one unary factor f_0(x_1) on the first pose x_1 that encodes our prior knowledge about x_1, and two binary factors that relate successive poses, respectively f_1(x_1, x_2; o_1) and f_2(x_2, x_3; o_2) where o_1 and o_2 represent odometry measurements.","type":"content","url":"/content/tutorial#id-2-1-modeling-with-factor-graphs","position":9},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.2 Creating a Factor Graph","lvl2":"2. Modeling Robot Motion"},"type":"lvl3","url":"/content/tutorial#id-2-2-creating-a-factor-graph","position":10},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.2 Creating a Factor Graph","lvl2":"2. Modeling Robot Motion"},"content":"The following C++ code, included in GTSAM as an example, creates the factor graph in Figure 3:// Create an empty nonlinear factor graph\nNonlinearFactorGraph graph;\n\n// Add a Gaussian prior on pose x_1\nPose2 priorMean(0.0, 0.0, 0.0);\nnoiseModel::Diagonal::shared_ptr priorNoise =\n  noiseModel::Diagonal::Sigmas(Vector3(0.3, 0.3, 0.1));\ngraph.add(PriorFactor<Pose2>(1, priorMean, priorNoise));\n\n// Add two odometry factors\nPose2 odometry(2.0, 0.0, 0.0);\nnoiseModel::Diagonal::shared_ptr odometryNoise =\n  noiseModel::Diagonal::Sigmas(Vector3(0.2, 0.2, 0.1));\ngraph.add(BetweenFactor<Pose2>(1, 2, odometry, odometryNoise));\ngraph.add(BetweenFactor<Pose2>(2, 3, odometry, odometryNoise));\n\nAbove, line 2 creates an empty factor graph. We then add the factor f_0(x_1) on lines 5-8 as an instance of PriorFactor<T>, a templated class provided in the slam subfolder, with T=Pose2. Its constructor takes a variable Key (in this case 1), a mean of type Pose2, created on Line 5, and a noise model for the prior density. We provide a diagonal Gaussian of type noiseModel::Diagonal by specifying three standard deviations in line 7, respectively 30 cm. on the robot’s position, and 0.1 radians on the robot’s orientation. Note that the Sigmas constructor returns a shared pointer, anticipating that typically the same noise models are used for many different factors.\n\nSimilarly, odometry measurements are specified as Pose2 on line 11, with a slightly different noise model defined on line 12-13. We then add the two factors f_1(x_1, x_2; o_1) and f_2(x_2, x_3; o_2) on lines 14-15, as instances of yet another templated class, BetweenFactor<T>, again with T=Pose2.\n\nWhen running the example (make OdometryExample.run on the command prompt), it will print out the factor graph as follows:Factor Graph:\nsize: 3\nFactor 0: PriorFactor on 1\nprior mean: (0, 0, 0)\nnoise model: diagonal sigmas [0.3; 0.3; 0.1];\nFactor 1: BetweenFactor(1,2)\nmeasured: (2, 0, 0)\nnoise model: diagonal sigmas [0.2; 0.2; 0.1];\nFactor 2: BetweenFactor(2,3)\nmeasured: (2, 0, 0)\nnoise model: diagonal sigmas [0.2; 0.2; 0.1];","type":"content","url":"/content/tutorial#id-2-2-creating-a-factor-graph","position":11},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.3 Factor Graphs vs. Values","lvl2":"2. Modeling Robot Motion"},"type":"lvl3","url":"/content/tutorial#id-2-3-factor-graphs-vs-values","position":12},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.3 Factor Graphs vs. Values","lvl2":"2. Modeling Robot Motion"},"content":"At this point it is instructive to emphasize two important design ideas underlying GTSAM:\n\nThe factor graph and its embodiment in code specify the joint probability distribution P(X|Z) over the entire trajectory X = {x_1, x_2, x_3} of the robot, rather than just the last pose. This smoothing view of the world gives GTSAM its name: “smoothing and mapping”. Later in this document we will talk about how we can also use GTSAM to do filtering (which you often do not want to do) or incremental inference (which we do all the time).\n\nA factor graph in GTSAM is just the specification of the probability density P(X|Z), and the corresponding FactorGraph class and its derived classes do not ever contain a “solution”. Rather, there is a separate type Values that is used to specify specific values for (in this case) x_1, x_2, and x_3, which can then be used to evaluate the probability (or, more commonly, the error) associated with particular values.\n\nThe latter point is often a point of confusion with beginning users of GTSAM. It helps to remember that when designing GTSAM we took a functional approach of classes corresponding to mathematical objects, which are usually immutable. You should think of a factor graph as a function to be applied to values—as the notation f(X) \\propto P(X|Z) implies—rather than as an object to be modified.","type":"content","url":"/content/tutorial#id-2-3-factor-graphs-vs-values","position":13},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.4 Non-linear Optimization in GTSAM","lvl2":"2. Modeling Robot Motion"},"type":"lvl3","url":"/content/tutorial#id-2-4-non-linear-optimization-in-gtsam","position":14},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.4 Non-linear Optimization in GTSAM","lvl2":"2. Modeling Robot Motion"},"content":"The listing below creates a Values instance, and uses it as the initial estimate to find the maximum a-posteriori (MAP) assignment for the trajectory X:// create (deliberately inaccurate) initial estimate\nValues initial;\ninitial.insert(1, Pose2(0.5, 0.0, 0.2));\ninitial.insert(2, Pose2(2.3, 0.1, -0.2));\ninitial.insert(3, Pose2(4.1, 0.1, 0.1));\n\n// optimize using Levenberg-Marquardt optimization\nValues result = LevenbergMarquardtOptimizer(graph, initial).optimize();\n\nLines 2-5 in Listing 2.4 create the initial estimate, and on line 8 we create a non-linear Levenberg-Marquardt style optimizer, and call optimize using default parameter settings. The reason why GTSAM needs to perform non-linear optimization is because the odometry factors f_1(x_1, x_2; o_1) and f_2(x_2, x_3; o_2) are non-linear, as they involve the orientation of the robot. This also explains why the factor graph we created in Listing 2.2 is of type NonlinearFactorGraph. The optimization class linearizes this graph, possibly multiple times, to minimize the non-linear squared error specified by the factors.\n\nThe relevant output from running the example is as follows:Initial Estimate:\nValues with 3 values:\nValue 1: (0.5, 0, 0.2)\nValue 2: (2.3, 0.1, -0.2)\nValue 3: (4.1, 0.1, 0.1)\n\nFinal Result:\nValues with 3 values:\nValue 1: (-1.8e-16, 8.7e-18, -9.1e-19)\nValue 2: (2, 7.4e-18, -2.5e-18)\nValue 3: (4, -1.8e-18, -3.1e-18)\n\nIt can be seen that, subject to very small tolerance, the ground truth solution x_1=(0, 0, 0), x_2=(2, 0, 0), and x_3=(4, 0, 0) is recovered.","type":"content","url":"/content/tutorial#id-2-4-non-linear-optimization-in-gtsam","position":15},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.5 Full Posterior Inference","lvl2":"2. Modeling Robot Motion"},"type":"lvl3","url":"/content/tutorial#id-2-5-full-posterior-inference","position":16},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"2.5 Full Posterior Inference","lvl2":"2. Modeling Robot Motion"},"content":"GTSAM can also be used to calculate the covariance matrix for each pose after incorporating the information from all measurements Z. Recognizing that the factor graph encodes the posterior density P(X|Z), the mean μ together with the covariance Σ for each pose x approximate the marginal posterior density P(x|Z). Note that this is just an approximation, as even in this simple case the odometry factors are actually non-linear in their arguments, and GTSAM only computes a Gaussian approximation to the true underlying posterior.\n\nThe following C++ code will recover the posterior marginals:// Query the marginals\ncout.precision(2);\nMarginals marginals(graph, result);\ncout << \"x1 covariance:\\n\" << marginals.marginalCovariance(1) << endl;\ncout << \"x2 covariance:\\n\" << marginals.marginalCovariance(2) << endl;\ncout << \"x3 covariance:\\n\" << marginals.marginalCovariance(3) << endl;\n\nThe relevant output from running the example is as follows:x1 covariance:\n    0.09     1.1e-47     5.7e-33\n    1.1e-47        0.09     1.9e-17\n    5.7e-33     1.9e-17        0.01\nx2 covariance:\n    0.13     4.7e-18     2.4e-18\n    4.7e-18        0.17        0.02\n    2.4e-18        0.02        0.02\nx3 covariance:\n    0.17     2.7e-17     8.4e-18\n    2.7e-17        0.37        0.06\n    8.4e-18        0.06        0.03\n\nWhat we see is that the marginal covariance P(x_1|Z) on x_1 is simply the prior knowledge on x_1, but as the robot moves the uncertainty in all dimensions grows without bound, and the y and θ components of the pose become (positively) correlated.\n\nAn important fact to note when interpreting these numbers is that covariance matrices are given in relative coordinates, not absolute coordinates. This is because internally GTSAM optimizes for a change with respect to a linearization point, as do all nonlinear optimization libraries.","type":"content","url":"/content/tutorial#id-2-5-full-posterior-inference","position":17},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"3. Robot Localization"},"type":"lvl2","url":"/content/tutorial#id-3-robot-localization","position":18},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"3. Robot Localization"},"content":"","type":"content","url":"/content/tutorial#id-3-robot-localization","position":19},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.1 Unary Measurement Factors","lvl2":"3. Robot Localization"},"type":"lvl3","url":"/content/tutorial#id-3-1-unary-measurement-factors","position":20},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.1 Unary Measurement Factors","lvl2":"3. Robot Localization"},"content":"In this section we add measurements to the factor graph that will help us actually localize the robot over time. The example also serves as a tutorial on creating new factor types.\n\n\n\nFigure 4:Robot localization factor graph with unary measurement factors at each time step.\n\nIn particular, we use unary measurement factors to handle external measurements. The example from Section 2 is not very useful on a real robot, because it only contains factors corresponding to odometry measurements. These are imperfect and will lead to quickly accumulating uncertainty on the last robot pose, at least in the absence of any external measurements (see Section 2.5). Figure 4 shows a new factor graph where the prior f_0(x_1) is omitted and instead we added three unary factors f_1(x_1; z_1), f_2(x_2; z_2), f_3(x_3; z_3) one for each localization measurement z_t, respectively. Such unary factors are applicable for measurements z_tthat depend only on the current robot pose, e.g., GPS readings, correlation of a laser range-finder in a pre-existing map, or indeed the presence of absence of ceiling lights (see \n\nDellaert & Thrun (1999) for that amusing example).","type":"content","url":"/content/tutorial#id-3-1-unary-measurement-factors","position":21},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.2 Defining Custom Factors","lvl2":"3. Robot Localization"},"type":"lvl3","url":"/content/tutorial#id-3-2-defining-custom-factors","position":22},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.2 Defining Custom Factors","lvl2":"3. Robot Localization"},"content":"In GTSAM, you can create custom unary factors by deriving a new class from the built-in class NoiseModelFactor1<T>, which implements a unary factor corresponding to a measurement likelihood with a Gaussian noise model, L(q; m) = \\exp \\left\\{ -\\frac{1}{2} \\| h(q) - m \\|^2_{\\Sigma} \\right\\} = f(q) where m is the measurement, q is the unknown variable, h(q) is a (possibly nonlinear) measurement function, and Σ is the noise covariance. Note that m is considered known above, and the likelihood L(q; m) will only ever be evaluated as a function of q, which explains why it is a unary factor f(q). It is always the unknown variable q that is either likely or unlikely, given the measurement.\n\nNote:\n\nMany people get this backwards, often misled by the conditional density notation P(m|q).\n\nIn fact, the likelihood L(q; m) is defined as any function of q proportional to P(m|q).\n\nListing 3.2 shows an example on how to define the custom factor class UnaryFactor which implements a “GPS-like” measurement likelihood:class UnaryFactor: public NoiseModelFactor1<Pose2> {\n  double mx_, my_; ///< X and Y measurements\n\npublic:\n  UnaryFactor(Key j, double x, double y, const SharedNoiseModel& model):\n    NoiseModelFactor1<Pose2>(model, j), mx_(x), my_(y) {}\n\n  Vector evaluateError(const Pose2& q,\n                       boost::optional<Matrix&> H = boost::none) const\n  {\n    const Rot2& R = q.rotation();\n    if (H) (*H) = (gtsam::Matrix(2, 3) <<\n            R.c(), -R.s(), 0.0,\n            R.s(), R.c(), 0.0).finished();\n    return (Vector(2) << q.x() - mx_, q.y() - my_).finished();\n  }\n};\n\nIn defining the derived class on line 1, we provide the template argument Pose2 to indicate the type of the variable q, whereas the measurement is stored as the instance variables mx_ and my_, defined on line 2. The constructor on lines 5-6 simply passes on the variable key j and the noise model to the superclass, and stores the measurement values provided. The most important function to has be implemented by every factor class is evaluateError(), which should return E(q) = h(q) - m which is done on line 12. Importantly, because we want to use this factor for nonlinear optimization (see e.g., \n\nKaess & Dellaert (2009) for details), whenever the optional argument H is provided, a Matrix reference, the function should assign the Jacobian of h(q), evauated at the provided value for q. This is done for this example on line 11. In this case, the Jacobian of the 2-dimensional function h, which just returns the position of the robot,h(q) = \\begin{bmatrix} q_x \\\\ q_y \\end{bmatrix}\n\nwith respect the 3-dimensional pose q = (q_x, q_y, q_\\theta), yields the following 2 \\times 3 matrix:H = \n\\begin{bmatrix}\n\\cos(q_\\theta) & -\\sin(q_\\theta) & 0 \\\\\n\\sin(q_\\theta) & \\cos(q_\\theta) & 0\n\\end{bmatrix}","type":"content","url":"/content/tutorial#id-3-2-defining-custom-factors","position":23},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl4":"Important Note","lvl3":"3.2 Defining Custom Factors","lvl2":"3. Robot Localization"},"type":"lvl4","url":"/content/tutorial#important-note","position":24},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl4":"Important Note","lvl3":"3.2 Defining Custom Factors","lvl2":"3. Robot Localization"},"content":"Many of our users, when attempting to create a custom factor, are initially surprised at the Jacobian matrix not agreeing with their intuition. For example, above you might simply expect a 2 \\times 3 diagonal matrix. This would be true for variables belonging to a vector space. However, in GTSAM we define the Jacobian more generally to be the matrix H such thath(q e^\\xi) \\approx h(q) + H \\xi\n\nwhere \\xi = (\\delta x, \\delta y, \\delta \\theta) is an incremental update and \\mathrm{exp} \\hat{\\xi} is the exponential map for the variable we want to update, In this case q \\in SE(2), where SE(2) is the group of 2D rigid transforms, implemented by Pose2. The exponential map for SE(2) can be approximated to first order as\\exp \\hat{\\xi} \\approx \n\\begin{bmatrix}\n1 & -\\delta\\theta & \\delta x \\\\\n\\delta\\theta & 1 & \\delta y \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\nwhen using the 3 \\times 3 matric representation for 2D poses, and henceh \\left( q e^\\xi \\right) \\approx \nh \\left( \n\\begin{bmatrix}\n\\cos(q_\\theta) & -\\sin(q_\\theta) & q_x \\\\\n\\sin(q_\\theta) & \\cos(q_\\theta) & q_y \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & -\\delta\\theta & \\delta x \\\\\n\\delta\\theta & 1 & \\delta y \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\right)\n=\n\\begin{bmatrix}\nq_x + \\cos(q_\\theta) \\delta x - \\sin(q_\\theta) \\delta y \\\\\nq_y + \\sin(q_\\theta) \\delta x + \\cos(q_\\theta) \\delta y\n\\end{bmatrix}\n\nwhich then explains the Jacobian H.","type":"content","url":"/content/tutorial#important-note","position":25},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.3 Using Custom Factors","lvl2":"3. Robot Localization"},"type":"lvl3","url":"/content/tutorial#id-3-3-using-custom-factors","position":26},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.3 Using Custom Factors","lvl2":"3. Robot Localization"},"content":"The following C++ code fragment illustrates how to create and add custom factors to a factor graph:// add unary measurement factors, like GPS, on all three poses\nnoiseModel::Diagonal::shared_ptr unaryNoise =\n noiseModel::Diagonal::Sigmas(Vector2(0.1, 0.1)); // 10cm std on x,y\ngraph.add(boost::make_shared<UnaryFactor>(1, 0.0, 0.0, unaryNoise));\ngraph.add(boost::make_shared<UnaryFactor>(2, 2.0, 0.0, unaryNoise));\ngraph.add(boost::make_shared<UnaryFactor>(3, 4.0, 0.0, unaryNoise));\n\nIn Listing 3.3, we create the noise model on line 2-3, which now specifies two standard deviations on the measurements m_x and m_y. On lines 4-6 we create shared_ptr versions of three newly created UnaryFactor instances, and add them to graph. GTSAM uses shared pointers to refer to factors in factor graphs, and boost::make_shared is a convenience function to simultaneously construct a class and create a shared_ptr to it. We obtain the factor graph from Figure 4.","type":"content","url":"/content/tutorial#id-3-3-using-custom-factors","position":27},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.4 Full Posterior Inference","lvl2":"3. Robot Localization"},"type":"lvl3","url":"/content/tutorial#id-3-4-full-posterior-inference","position":28},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"3.4 Full Posterior Inference","lvl2":"3. Robot Localization"},"content":"The three GPS factors are enough to fully constrain all unknown poses and tie them to a “global” reference frame, including the three unknown orientations. If not, GTSAM would have exited with a singular matrix exception. The marginals can be recovered exactly as in Section 2.5, and the solution and marginal covariances are now given by the following:Final Result:\nValues with 3 values:\nValue 1: (-1.5e-14, 1.3e-15, -1.4e-16)\nValue 2: (2, 3.1e-16, -8.5e-17)\nValue 3: (4, -6e-16, -8.2e-17)\n\nx1 covariance:\n    0.0083      4.3e-19     -1.1e-18\n    4.3e-19       0.0094      -0.0031\n    -1.1e-18      -0.0031       0.0082\nx2 covariance:\n    0.0071      2.5e-19     -3.4e-19\n    2.5e-19       0.0078      -0.0011\n    -3.4e-19      -0.0011       0.0082\nx3 covariance:\n    0.0083     4.4e-19     1.2e-18\n    4.4e-19      0.0094      0.0031\n    1.2e-18      0.0031       0.018\n\nComparing this with the covariance matrices in Section 2.5, we can see that the uncertainty no longer grows without bounds as measurement uncertainty accumulates. Instead, the “GPS” measurements more or less constrain the poses evenly, as expected.\n\nFigure 5:![Odometry marginals ../../Assets/Images/tutorial/5_Odometry.png)\n\n![Localization Marginals ../../Assets/Images/tutorial/5_Localization.png)\n\nComparing the marginals resulting from the “odometry” factor graph in Figure 3 and the “localization” factor graph in Figure 4.\n\nIt helps a lot when we view this graphically, as in Figure 5, where I show the marginals on position as 5-sigma covariance ellipses that contain 99.9996% of all probability mass. For the odometry marginals, it is immediately apparent from the figure that (1) the uncertainty on pose keeps growing, and (2) the uncertainty on angular odometry translates into increasing uncertainty on y. The localization marginals, in contrast, are constrained by the unary factors and are all much smaller. In addition, while less apparent, the uncertainty on the middle pose is actually smaller as it is constrained by odometry from two sides.\nYou might now be wondering how we produced these figures. The answer is via the MATLAB interface of GTSAM, which we will demonstrate in the next section.","type":"content","url":"/content/tutorial#id-3-4-full-posterior-inference","position":29},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"4. PoseSLAM"},"type":"lvl2","url":"/content/tutorial#id-4-poseslam","position":30},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"4. PoseSLAM"},"content":"","type":"content","url":"/content/tutorial#id-4-poseslam","position":31},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"4.1 Loop Closure Constraints","lvl2":"4. PoseSLAM"},"type":"lvl3","url":"/content/tutorial#id-4-1-loop-closure-constraints","position":32},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"4.1 Loop Closure Constraints","lvl2":"4. PoseSLAM"},"content":"The simplest instantiation of a SLAM problem is PoseSLAM, which avoids building an explicit map of the environment. The goal of SLAM is to simultaneously localize a robot and map the environment given incoming sensor measurements (\n\nDurrant-Whyte & Bailey (2006)). Besides wheel odometry, one of the most popular sensors for robots moving on a plane is a 2D laser-range finder, which provides both odometry constraints between successive poses, and loop-closure constraints when the robot re-visits a previously explored part of the environment.\n\n\n\nFigure 6:Factor graph for PoseSLAM.\n\nA factor graph example for PoseSLAM is shown in Figure 6. The following C++ code, included in GTSAM as an example, creates this factor graph in code:NonlinearFactorGraph graph;\nnoiseModel::Diagonal::shared_ptr priorNoise =\n  noiseModel::Diagonal::Sigmas(Vector3(0.3, 0.3, 0.1));\ngraph.add(PriorFactor<Pose2>(1, Pose2(0, 0, 0), priorNoise));\n\n// Add odometry factors\nnoiseModel::Diagonal::shared_ptr model =\n  noiseModel::Diagonal::Sigmas(Vector3(0.2, 0.2, 0.1));\ngraph.add(BetweenFactor<Pose2>(1, 2, Pose2(2, 0, 0     ), model));\ngraph.add(BetweenFactor<Pose2>(2, 3, Pose2(2, 0, M_PI_2), model));\ngraph.add(BetweenFactor<Pose2>(3, 4, Pose2(2, 0, M_PI_2), model));\ngraph.add(BetweenFactor<Pose2>(4, 5, Pose2(2, 0, M_PI_2), model));\n\n// Add the loop closure constraint\ngraph.add(BetweenFactor<Pose2>(5, 2, Pose2(2, 0, M_PI_2), model));\n\nAs before, lines 1-4 create a nonlinear factor graph and add the unary factor f_0(x_1). As the robot travels through the world, it creates binary factors\nf_t(x_t, x_{t+1}) corresponding to odometry, added to the graph in lines 6-12 (Note that M_PI_2 refers to pi/2). But line 15 models a different event: a loop closure. For example, the robot might recognize the same location using vision or a laser range finder, and calculate the geometric pose constraint to when it first visited this location. This is illustrated for poses x_5 and x_2, and generates the (red) loop closing factor f_5(x_5, x_2).\n\n\n\nFigure 7:The result of running optimize on the factor graph in Figure 6.\n\nWe can optimize this factor graph as before, by creating an initial estimate of type Values, and creating and running an optimizer. The result is shown graphically in Figure 7, along with covariance ellipses shown in green. These 5-sigma covariance ellipses in 2D indicate the marginal over position, over all possible orientations, and show the area which contain 99.9996% of the probability mass. The graph shows in a clear manner that the uncertainty on pose x_5 is now much less than if there would be only odometry measurements. The pose with the highest uncertainty, x_4, is the one furthest away from the unary constraint f_0(x_1), which is the only factor tying the graph to a global coordinate frame.\n\nThe figure above was created using an interface that allows you to use GTSAM from within MATLAB, which provides for visualization and rapid development. We discuss this next.\n\n4.2 Using the MATLAB Interface\nA large subset of the GTSAM functionality can be accessed through wrapped classes from within MATLAB. The following code excerpt is the MATLAB equivalent of the C++ code in Listing 4.1:graph = NonlinearFactorGraph;\npriorNoise = noiseModel.Diagonal.Sigmas([0.3; 0.3; 0.1]);\ngraph.add(PriorFactorPose2(1, Pose2(0, 0, 0), priorNoise));\n\n%% Add odometry factors\nmodel = noiseModel.Diagonal.Sigmas([0.2; 0.2; 0.1]);\ngraph.add(BetweenFactorPose2(1, 2, Pose2(2, 0, 0   ), model));\ngraph.add(BetweenFactorPose2(2, 3, Pose2(2, 0, pi/2), model));\ngraph.add(BetweenFactorPose2(3, 4, Pose2(2, 0, pi/2), model));\ngraph.add(BetweenFactorPose2(4, 5, Pose2(2, 0, pi/2), model));\n\n%% Add pose constraint\ngraph.add(BetweenFactorPose2(5, 2, Pose2(2, 0, pi/2), model));\n\nNote that the code is almost identical, although there are a few syntax and naming differences:\n\nObjects are created by calling a constructor instead of allocating them on the heap.\n\nNamespaces are done using dot notation, i.e., noiseModel::Diagonal::SigmasClasses becomes noiseModel.Diagonal.Sigmas.\n\nVector and Matrix classes in C++ are just vectors/matrices in MATLAB.\n\nAs templated classes do not exist in MATLAB, these have been hardcoded in the GTSAM interface, e.g., PriorFactorPose2 corresponds to the C++ class PriorFactor<Pose2>, etc.\n\nAfter executing the code, you can call whos on the MATLAB command prompt to see the objects created. Note that the indicated Class corresponds to the wrapped C++ classes:>> whos\nName                 Size            Bytes  Class\ngraph                1x1               112  gtsam.NonlinearFactorGraph\npriorNoise           1x1               112  gtsam.noiseModel.Diagonal\nmodel                1x1               112  gtsam.noiseModel.Diagonal\ninitialEstimate      1x1               112  gtsam.Values\noptimizer            1x1               112  gtsam.LevenbergMarquardtOptimizer\n\nIn addition, any GTSAM object can be examined in detail, yielding identical output to C++:>> priorNoise\ndiagonal sigmas [0.3; 0.3; 0.1];\n\n>> graph\nsize: 6\nfactor 0: PriorFactor on 1\nprior mean: (0, 0, 0)\nnoise model: diagonal sigmas [0.3; 0.3; 0.1];\nfactor 1: BetweenFactor(1,2)\nmeasured: (2, 0, 0)\nnoise model: diagonal sigmas [0.2; 0.2; 0.1];\nfactor 2: BetweenFactor(2,3)\nmeasured: (2, 0, 1.6)\nnoise model: diagonal sigmas [0.2; 0.2; 0.1];\nfactor 3: BetweenFactor(3,4)\nmeasured: (2, 0, 1.6)\nnoise model: diagonal sigmas [0.2; 0.2; 0.1];\nfactor 4: BetweenFactor(4,5)\nmeasured: (2, 0, 1.6)\nnoise model: diagonal sigmas [0.2; 0.2; 0.1];\nfactor 5: BetweenFactor(5,2)\nmeasured: (2, 0, 1.6)\nnoise model: diagonal sigmas [0.2; 0.2; 0.1];\n\nAnd it does not stop there: we can also call some of the functions defined for factor graphs. E.g.,>> graph.error(initialEstimate)\nans =\n20.1086\n\n>> graph.error(result)\nans =\n8.2631e-18\n\ncomputes the sum-squared error \\frac{1}{2} \\sum_i \\| h_i(X_i) - z_i \\|^2_{\\Sigma} before and after optimization.","type":"content","url":"/content/tutorial#id-4-1-loop-closure-constraints","position":33},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"4.3 Reading and Optimizing Pose Graphs","lvl2":"4. PoseSLAM"},"type":"lvl3","url":"/content/tutorial#id-4-3-reading-and-optimizing-pose-graphs","position":34},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"4.3 Reading and Optimizing Pose Graphs","lvl2":"4. PoseSLAM"},"content":"\n\nFigure 8:MATLAB plot of small Manhattan world example with 100 poses (due to Ed Olson). The initial estimate is shown in green. The optimized trajectory, with covariance ellipses, in blue.\n\nThe ability to work in MATLAB adds a much quicker development cycle, and effortless graphical output. The optimized trajectory in Figure 8 was produced by the code below, in which load2D() reads TORO files. To see how plotting is done, refer to the full source code.%% Initialize graph, initial estimate, and odometry noise\ndatafile = findExampleDataFile('w100.graph');\nmodel = noiseModel.Diagonal.Sigmas([0.05; 0.05; 5*pi/180]);\n[graph,initial] = load2D(datafile, model);\n\n%% Add a Gaussian prior on pose x_0\npriorMean = Pose2(0, 0, 0);\npriorNoise = noiseModel.Diagonal.Sigmas([0.01; 0.01; 0.01]);\ngraph.add(PriorFactorPose2(0, priorMean, priorNoise));\n\n%% Optimize using Levenberg-Marquardt optimization and get marginals\noptimizer = LevenbergMarquardtOptimizer(graph, initial);\nresult = optimizer.optimizeSafely;\nmarginals = Marginals(graph, result);","type":"content","url":"/content/tutorial#id-4-3-reading-and-optimizing-pose-graphs","position":35},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"4.4 PoseSLAM in 3D","lvl2":"4. PoseSLAM"},"type":"lvl3","url":"/content/tutorial#id-4-4-poseslam-in-3d","position":36},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"4.4 PoseSLAM in 3D","lvl2":"4. PoseSLAM"},"content":"PoseSLAM can easily be extended to 3D poses, but some care is needed to update 3D rotations. GTSAM supports both quaternions and 3 \\times 3 rotation matrices to represent 3D rotations. The selection is made via the compile flag GTSAM_USE_QUATERNIONS.\n\n\n\nFigure 9:3D plot of sphere example (due to Michael Kaess). The very wrong initial estimate, derived from odometry, is shown in green. The optimized trajectory is shown red. Code below:%% Initialize graph, initial estimate, and odometry noise\ndatafile = findExampleDataFile('sphere2500.txt');\nmodel = noiseModel.Diagonal.Sigmas([5*pi/180; 5*pi/180; 5*pi/180; 0.05; 0.05; 0.05]);\n[graph,initial] = load3D(datafile, model, true, 2500);\nplot3DTrajectory(initial, 'g-', false); % Plot Initial Estimate\n\n%% Read again, now with all constraints, and optimize\ngraph = load3D(datafile, model, false, 2500);\ngraph.add(NonlinearEqualityPose3(0, initial.atPose3(0)));\noptimizer = LevenbergMarquardtOptimizer(graph, initial);\nresult = optimizer.optimizeSafely();\nplot3DTrajectory(result, 'r-', false); axis equal;","type":"content","url":"/content/tutorial#id-4-4-poseslam-in-3d","position":37},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"5. Landmark-based SLAM"},"type":"lvl2","url":"/content/tutorial#id-5-landmark-based-slam","position":38},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"5. Landmark-based SLAM"},"content":"","type":"content","url":"/content/tutorial#id-5-landmark-based-slam","position":39},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.1 Basics","lvl2":"5. Landmark-based SLAM"},"type":"lvl3","url":"/content/tutorial#id-5-1-basics","position":40},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.1 Basics","lvl2":"5. Landmark-based SLAM"},"content":"\n\nFigure 10:Factor graph for landmark-based SLAM\n\nIn landmark-based SLAM, we explicitly build a map with the location of observed landmarks, which introduces a second type of variable in the factor graph besides robot poses. An example factor graph for a landmark-based SLAM example is shown in Figure 10, which shows the typical connectivity: poses are connected in an odometry Markov chain, and landmarks are observed from multiple poses, inducing binary factors. In addition, the pose x_1 has the usual prior on it.\n\n\n\nFigure 11:The optimized result along with covariance ellipses for both poses (in green) and landmarks (in blue). Also shown are the trajectory (red) and landmark sightings (cyan).\n\nThe factor graph from Figure 10 can be created using the MATLAB code in Listing 5.1. As before, on line 2 we create the factor graph, and Lines 8-18 create the prior/odometry chain we are now familiar with. However, the code on lines 20-25 is new: it creates three measurement factors, in this case “bearing/range” measurements from the pose to the landmark.% Create graph container and add factors to it\ngraph = NonlinearFactorGraph;\n\n% Create keys for variables\ni1 = symbol('x',1); i2 = symbol('x',2); i3 = symbol('x',3);\nj1 = symbol('l',1); j2 = symbol('l',2);\n\n% Add prior\npriorMean = Pose2(0.0, 0.0, 0.0); % prior at origin\npriorNoise = noiseModel.Diagonal.Sigmas([0.3; 0.3; 0.1]);\n% add directly to graph\ngraph.add(PriorFactorPose2(i1, priorMean, priorNoise));\n\n% Add odometry\nodometry = Pose2(2.0, 0.0, 0.0);\nodometryNoise = noiseModel.Diagonal.Sigmas([0.2; 0.2; 0.1]);\ngraph.add(BetweenFactorPose2(i1, i2, odometry, odometryNoise));\ngraph.add(BetweenFactorPose2(i2, i3, odometry, odometryNoise));\n\n% Add bearing/range measurement factors\ndegrees = pi/180;\nbrNoise = noiseModel.Diagonal.Sigmas([0.1; 0.2]);\ngraph.add(BearingRangeFactor2D(i1, j1, Rot2(45*degrees), sqrt(8), brNoise));\ngraph.add(BearingRangeFactor2D(i2, j1, Rot2(90*degrees), 2, brNoise));\ngraph.add(BearingRangeFactor2D(i3, j2, Rot2(90*degrees), 2, brNoise));","type":"content","url":"/content/tutorial#id-5-1-basics","position":41},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.2 Of Keys and Symbols","lvl2":"5. Landmark-based SLAM"},"type":"lvl3","url":"/content/tutorial#id-5-2-of-keys-and-symbols","position":42},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.2 Of Keys and Symbols","lvl2":"5. Landmark-based SLAM"},"content":"The only unexplained code is on lines 4-6: here we create integer keys for the poses and landmarks using the symbol() function. In GTSAM, we address all variables using the Key type, which is just a typedef to size_t  . The keys do not have to be numbered continuously, but they do have to be unique within a given factor graph. For factor graphs with different types of variables, we provide the symbol() function in MATLAB, and the Symbol type in C++, to help you create (large) integer keys that are far apart in the space of possible keys, so you don’t have to think about starting the point numbering at some arbitrary offset. To create a symbol key you simply provide a character and an integer index. You can use base 0 or 1, or use arbitrary indices: it does not matter. In the code above, we we use ‘x’ for poses, and ‘l’ for landmarks.\n\nThe optimized result for the factor graph created by Listing 5.1 is shown in Figure 11, and it is readily apparent that the landmark l_1 with two measurements is better localized. In MATLAB we can also examine the actual numerical values, and doing so reveals some more GTSAM magic:result Values with 5 values: l1: (2, 2) l2: (4, 2) x1: (-1.8e-16, 5.1e-17, -1.5e-17) x2: (2, -5.8e-16, -4.6e-16) x3: (4, -3.1e-15, -4.6e-16)\n\nIndeed, the keys generated by symbol are automatically detected by the print method in the Values class, and rendered in human-readable form “x1”, “l2”, etc, rather than as large, unwieldy integers. This magic extends to most factors and other classes where the Key type is used.","type":"content","url":"/content/tutorial#id-5-2-of-keys-and-symbols","position":43},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.3 A Larger Example","lvl2":"5. Landmark-based SLAM"},"type":"lvl3","url":"/content/tutorial#id-5-3-a-larger-example","position":44},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.3 A Larger Example","lvl2":"5. Landmark-based SLAM"},"content":"\n\nFigure 12:A larger example with about 100 poses and 30 or so landmarks, as produced by gtsam_examples/PlanarSLAMExample_graph.m\n\nGTSAM comes with a slightly larger example that is read from a .graph file by PlanarSLAMExample_graph.m, shown in Figure 12. To not clutter the figure only the marginals are shown, not the lines of sight. This example, with 119 (multivariate) variables and 517 factors optimizes in less than 10 ms.","type":"content","url":"/content/tutorial#id-5-3-a-larger-example","position":45},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.4 A Real-World Example","lvl2":"5. Landmark-based SLAM"},"type":"lvl3","url":"/content/tutorial#id-5-4-a-real-world-example","position":46},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"5.4 A Real-World Example","lvl2":"5. Landmark-based SLAM"},"content":"\n\nFigure 13:Small section of optimized trajectory and landmarks (trees detected in a laser range finder scan) from data recorded in Sydney’s Victoria Park (dataset due to Jose Guivant, U. Sydney).\n\nA real-world example is shown in Figure 13, using data from a well known dataset collected in Sydney’s Victoria Park, using a truck equipped with a laser range-finder. The covariance matrices in this figure were computed very efficiently, as explained in detail in \n\nKaess & Dellaert (2009). The exact covariances (blue, smaller ellipses) obtained by our fast algorithm coincide with the exact covariances based on full inversion (orange, mostly hidden by blue). The much larger conservative covariance estimates (green, large ellipses) were based on our earlier work in \n\nKaess & Dellaert (2008).","type":"content","url":"/content/tutorial#id-5-4-a-real-world-example","position":47},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"6. Structure from Motion"},"type":"lvl2","url":"/content/tutorial#id-6-structure-from-motion","position":48},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"6. Structure from Motion"},"content":"\n\nFigure 14:An optimized “Structure from Motion” with 10 cameras arranged in a circle, observing the 8 vertices of a 20 \\times 20 \\times 20 cube centered around the origin. The camera is rendered with color-coded axes, (RGB for XYZ) and the viewing direction is is along the positive Z-axis. Also shown are the 3D error covariance ellipses for both cameras and points.\n\nStructure from Motion (SFM) is a technique to recover a 3D reconstruction of the environment from corresponding visual features in a collection of unordered images, see Figure 14. In GTSAM this is done using exactly the same factor graph framework, simply using SFM-specific measurement factors. In particular, there is a projection factor that calculates the reprojection error f(x_i, p_j, z_{ij}, K) for a given camera pose x_i (a Pose3) and a point p_j ( a Point3). The factor is parameterized by the 2D measurement z_{ij} (a Point 2), and known calibration parameters K (of type Cal3_S2). The following listing shows how to create the factor graph:%% Add factors for all measurements\nnoise = noiseModel.Isotropic.Sigma(2, measurementNoiseSigma);\nfor i = 1:length(Z),\n    for k = 1:length(Z{i})\n        j = J{i}{k};\n        G.add(GenericProjectionFactorCal3_S2(\n              Z{i}{k}, noise, symbol('x', i), symbol('p', j), K));\n    end\nend\n\nIn Listing 6, assuming that the factor graph was already created, we add measurement factors in the double loop. We loop over images with index i, and in this example the data is given as two cell arrays: Z{i} specifies a set of measurements z_k in image i, and J{i} specifies the corresponding point index. The specific factor type we use is a GenericProjectionFactorCal3_S2, which is the MATLAB equivalent of the C++ class GenericProjectionFactor<Cal3_S2>, where Cal3_S2 is the camera calibration type we choose to use (the standard, no-radial distortion, 5 parameter calibration matrix). As before landmark-based SLAM (Section 5), here we use symbol keys except we now use the character ‘p’ to denote points, rather than ‘l’ for landmark.","type":"content","url":"/content/tutorial#id-6-structure-from-motion","position":49},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"Important note","lvl2":"6. Structure from Motion"},"type":"lvl3","url":"/content/tutorial#important-note-1","position":50},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"Important note","lvl2":"6. Structure from Motion"},"content":"A very tricky and difficult part of making SFM work is (a) data association, and (b) initialization. GTSAM does neither of these things for you: it simply provides the “bundle adjustment” optimization. In the example, we simply assume the data association is known (it is encoded in the J sets), and we initialize with the ground truth, as the intent of the example is simply to show you how to set up the optimization problem.","type":"content","url":"/content/tutorial#important-note-1","position":51},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"7. iSAM: Incremental Smoothing and Mapping"},"type":"lvl2","url":"/content/tutorial#id-7-isam-incremental-smoothing-and-mapping","position":52},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"7. iSAM: Incremental Smoothing and Mapping"},"content":"GTSAM provides an incremental inference algorithm based on a more advanced graphical model, the Bayes tree, which is kept up to date by the iSAM algorithm (incremental Smoothing and Mapping, see \n\nKaess & Dellaert (2008); \n\nKaess & Dellaert (2012) for an in-depth treatment). For mobile robots operating in real-time it is important to have access to an updated map as soon as new sensor measurements come in. iSAM keeps the map up-to-date in an efficient manner.\n\nListing 7 shows how to use iSAM in a simple visual SLAM example. In line 1-2 we create a NonlinearISAM object which will relinearize and reorder the variables every 3 steps. The corect value for this parameter depends on how non-linear your problem is and how close you want to be to gold-standard solution at every step. In iSAM 2.0, this parameter is not needed, as iSAM2 automatically determines when linearization is needed and for which variables.\n\nThe example involves eight 3D points that are seen from eight successive camera poses. Hence in the first step -which is omitted here- all eight landmarks and the first pose are properly initialized. In the code this is done by perturbing the known ground truth, but in a real application great care is needed to properly initialize poses and landmarks, especially in a monocular sequence.int relinearizeInterval = 3;\nNonlinearISAM isam(relinearizeInterval);\n\n// ... first frame initialization omitted ...\n\n// Loop over the different poses, adding the observations to iSAM\nfor (size_t i = 1; i < poses.size(); ++i) {\n\n  // Add factors for each landmark observation\n  NonlinearFactorGraph graph;\n  for (size_t j = 0; j < points.size(); ++j) {\n    graph.add(\n      GenericProjectionFactor<Pose3, Point3, Cal3_S2>\n        (z[i][j], noise,Symbol('x', i), Symbol('l', j), K)\n    );\n  }\n\n  // Add an initial guess for the current pose\n  Values initialEstimate;\n  initialEstimate.insert(Symbol('x', i), initial_x[i]);\n\n  // Update iSAM with the new factors\n  isam.update(graph, initialEstimate);\n }\n\nThe remainder of the code illustrates a typical iSAM loop:\n\nCreate factors for new measurements. Here, in lines 9-18, a small NonlinearFactorGraph is created to hold the new factors of type GenericProjectionFactor<Pose3, Point3, Cal3_S2>.\n\nCreate an initial estimate for all newly introduced variables. In this small example, all landmarks have been observed in frame 1 and hence the only new variable that needs to be initialized at each time step is the new pose. This is done in lines 20-22. Note we assume a good initial estimate is available as initial_x[i].\n\nFinally, we call isam.update(), which takes the factors and initial estimates, and incrementally updates the solution, which is available through the method isam.estimate(), if desired.","type":"content","url":"/content/tutorial#id-7-isam-incremental-smoothing-and-mapping","position":53},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"8. More Applications"},"type":"lvl2","url":"/content/tutorial#id-8-more-applications","position":54},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"8. More Applications"},"content":"While a detailed discussion of all the things you can do with GTSAM will take us too far, below is a small survey of what you can expect to do, and which we did using GTSAM.","type":"content","url":"/content/tutorial#id-8-more-applications","position":55},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.1 Conjugate Gradient Optimization","lvl2":"8. More Applications"},"type":"lvl3","url":"/content/tutorial#id-8-1-conjugate-gradient-optimization","position":56},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.1 Conjugate Gradient Optimization","lvl2":"8. More Applications"},"content":"\n\nFigure 15:A map of Beijing, with a spanning tree shown in black, and the remaining loop-closing constraints shown in red. A spanning tree can be used as a preconditioner by GTSAM.\n\nGTSAM also includes efficient preconditioned conjugate gradients (PCG) methods for solving large-scale SLAM problems. While direct methods, popular in the literature, exhibit quadratic convergence and can be quite efficient for sparse problems, they typically require a lot of storage and efficient elimination orderings to be found. In contrast, iterative optimization methods only require access to the gradient and have a small memory footprint, but can suffer from poor convergence. Our method, subgraph preconditioning, explained in detail in \n\nDellaert & Thorpe (2010); \n\nJian & Dellaert (2011), combines the advantages of direct and iterative methods, by identifying a sub-problem that can be easily solved using direct methods, and solving for the remaining part using PCG. The easy sub-problems correspond to a spanning tree, a planar subgraph, or any other substructure that can be efficiently solved. An example of such a subgraph is shown in Figure 15.","type":"content","url":"/content/tutorial#id-8-1-conjugate-gradient-optimization","position":57},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.2 Visual Odometry","lvl2":"8. More Applications"},"type":"lvl3","url":"/content/tutorial#id-8-2-visual-odometry","position":58},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.2 Visual Odometry","lvl2":"8. More Applications"},"content":"A gentle introduction to vision-based sensing is Visual Odometry (abbreviated VO, see e.g. \n\nNistér & Bergen (2004)), which provides pose constraints between successive robot poses by tracking or associating visual features in successive images taken by a camera mounted rigidly on the robot. GTSAM includes both C++ and MATLAB example code, as well as VO-specific factors to help you on the way.","type":"content","url":"/content/tutorial#id-8-2-visual-odometry","position":59},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.3 Visual SLAM","lvl2":"8. More Applications"},"type":"lvl3","url":"/content/tutorial#id-8-3-visual-slam","position":60},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.3 Visual SLAM","lvl2":"8. More Applications"},"content":"Visual SLAM (see e.g., \n\nDavison (2003)) is a SLAM variant where 3D points are observed by a camera as the camera moves through space, either mounted on a robot or moved around by hand. GTSAM, and particularly iSAM (see below), can easily be adapted to be used as the back-end optimizer in such a scenario.","type":"content","url":"/content/tutorial#id-8-3-visual-slam","position":61},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.4 Fixed-lag Smoothing and Filtering","lvl2":"8. More Applications"},"type":"lvl3","url":"/content/tutorial#id-8-4-fixed-lag-smoothing-and-filtering","position":62},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.4 Fixed-lag Smoothing and Filtering","lvl2":"8. More Applications"},"content":"GTSAM can easily perform recursive estimation, where only a subset of the poses are kept in the factor graph, while the remaining poses are marginalized out. In all examples above we explicitly optimize for all variables using all available measurements, which is called Smoothing because the trajectory is “smoothed” out, and this is where GTSAM got its name (GT Smoothing and Mapping). When instead only the last few poses are kept in the graph, one speaks of Fixed-lag Smoothing. Finally, when only the single most recent poses is kept, one speaks of Filtering, and indeed the original formulation of SLAM was filter-based (\n\nSmith & Cheeseman (1988)).","type":"content","url":"/content/tutorial#id-8-4-fixed-lag-smoothing-and-filtering","position":63},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.5 Discrete Variables and HMMs","lvl2":"8. More Applications"},"type":"lvl3","url":"/content/tutorial#id-8-5-discrete-variables-and-hmms","position":64},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl3":"8.5 Discrete Variables and HMMs","lvl2":"8. More Applications"},"content":"Finally, factor graphs are not limited to continuous variables: GTSAM can also be used to model and solve discrete optimization problems. For example, a Hidden Markov Model (HMM) has the same graphical model structure as the Robot Localization problem from Section 2, except that in an HMM the variables are discrete. GTSAM can optimize and perform inference for discrete models.","type":"content","url":"/content/tutorial#id-8-5-discrete-variables-and-hmms","position":65},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"Acknowledgements"},"type":"lvl2","url":"/content/tutorial#acknowledgements","position":66},{"hierarchy":{"lvl1":"Factor Graphs and GTSAM","lvl2":"Acknowledgements"},"content":"GTSAM was made possible by the efforts of many collaborators at Georgia Tech and elsewhere, including but not limited to Doru Balcan, Chris Beall, Alex Cunningham, Alireza Fathi, Eohan George, Viorela Ila, Yong-Dian Jian, Michael Kaess, Kai Ni, Carlos Nieto, Duy-Nguyen Ta, Manohar Paluri, Christian Potthast, Richard Roberts, Grant Schindler, and Stephen Williams. In addition, Paritosh Mohan helped me with the manual. Many thanks all for your hard work!\n\nGTSAM also allows you to wrap your own custom-made classes, although this is out of the scope of this manual. The following code excerpt is the MATLAB equivalent of the C++ code in Listing 4.1:\n\na 32 or 64 bit integer, depending on your platform","type":"content","url":"/content/tutorial#acknowledgements","position":67}]}